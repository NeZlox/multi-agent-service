"""
Agenda AI agent implementation.

Provides health check and message handling logic for the Agenda service.
"""

from __future__ import annotations

from personal_growth_sdk.lib.schemas.health_check_schema import HealthStatus

# Avoid importing from __init__.py to prevent circular import issues
from app.application.ai_agent_gateway.ai_agent_interface import AIAgentGatewayInterface
from app.config.base_settings import get_settings
from app.lib.http import HttpService

__all__ = ['AgendaAgent']

settings = get_settings()


class AgendaAgent(AIAgentGatewayInterface):
    """
    Concrete implementation of AIAgentGatewayInterface for the Agenda service.

    This class provides integration with the external Agenda AI system.
    It supports health checking and simple message relay logic.
    """

    name = 'agenda'
    agent_base_url = settings.app.AGENDA_SERVICE_URL

    @classmethod
    async def _get_health_status(cls) -> tuple[HealthStatus, dict | None]:
        """
        Perform a basic GET /health request to the Agenda service.

        Returns:
            A tuple (HealthStatus.OK, None) if the request succeeds.
        """

        await HttpService.raw_request(
            'GET',
            f'{cls.agent_base_url}/health'
        )

        return HealthStatus.OK, None

    @classmethod
    async def generate(
            cls,
            chat_id: int,  # noqa: ARG003
            new_message: str
    ) -> str:
        """
        Generates a reply based on the given user message.

        Note: This is a stub implementation that echoes the message.
        The actual LLM logic should be implemented by the remote Agenda service.

        Args:
            chat_id: Identifier of the current chat session.
            new_message: Message received from the user.

        Returns:
            Response string generated by the assistant.
        """

        return new_message
